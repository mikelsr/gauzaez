package lexer

import (
	"bytes"
	"fmt"
	"log"

	"bitbucket.org/mikelsr/gauzaez/lexer/automaton"
	"github.com/olekukonko/tablewriter"
)

// TokenTable stores information about tokens generated by Lexer
type TokenTable struct {
	Tokens   []automaton.Token
	Values   []string
	Lines    []uint
	LinePosI []uint
	LinePosE []uint
}

// write line to printable table
func (tt *TokenTable) writeToken(t automaton.Token, v string, l uint, posi uint, pose uint) {
	log.Printf("Writing: %v, '%s', %d, %d, %d", t, escape(v), l, posi, pose)
	tt.Tokens = append(tt.Tokens, t)
	tt.Values = append(tt.Values, escape(v))
	tt.Lines = append(tt.Lines, l)
	tt.LinePosI = append(tt.LinePosI, posi)
	tt.LinePosE = append(tt.LinePosE, pose)
}

// Convert TokenTable to string
func (tt *TokenTable) String() string {
	tableStr := bytes.NewBufferString("")
	table := tablewriter.NewWriter(tableStr)
	table.SetAlignment(tablewriter.ALIGN_LEFT)
	table.SetHeader([]string{"Token", "Value", "Line",
		"Start Column", "End Column"})
	for i, t := range tt.Tokens {
		table.Append([]string{string(t), tt.Values[i], fmt.Sprint(tt.Lines[i]),
			fmt.Sprint(tt.LinePosI[i]), fmt.Sprint(tt.LinePosE[i])})
	}
	table.Render()
	return tableStr.String()
}

// escape printable characters
func escape(s string) string {
	switch s {
	case "\n":
		return "\\n"
	case "\t":
		return "\\t"
	default:
		return s
	}
}
